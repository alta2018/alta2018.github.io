<!DOCTYPE html>
<html lang="en">
	<head>
    	<meta charset="utf-8">
    	<meta http-equiv="X-UA-Compatible" content="IE=edge">
    	<meta name="viewport" content="width=device-width, initial-scale=1">
    	<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    	<meta name="description" content="">
    	<meta name="author" content="">
    	<link rel="icon" href="logos/logo_sm.jpg">

    	<title>ALTA 2018</title>

    	<!-- Bootstrap core CSS -->
    	<link href="css/bootstrap.css" rel="stylesheet">

    	<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    	<!--[if lt IE 9]>
      	<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      	<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    	<![endif]-->
    	<script src="http://www.w3schools.com/lib/w3data.js"></script>
  	</head>

  	<body>
    	<div class="jumbotron">
      		<div class="container">
        	<br>
        	<br>
        	<h2>16th Annual Workshop of <br>The Australasian Language Technology Association</h2>
		<h3>The University of Otago, Dunedin, New Zealand</h3>
		<h3>10th - 12th December 2018</h3>
      		</div>
    	</div>
    
    	<nav class="navbar navbar-inverse navbar-fixed-top">
      	<div class="container">
        	<div class="navbar-header">
          	<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            	<span class="sr-only">Toggle navigation</span>
            	<span class="icon-bar"></span>
            	<span class="icon-bar"></span>
            	<span class="icon-bar"></span>
          	</button>
          	<a class="navbar-brand" href="index.html">Home</a>
          	<a class="navbar-brand" href="accepted_papers.html">Programme</a>
          	<a class="navbar-brand" href="attending.html">Attending</a>
          	<a class="navbar-brand" href="tutorials.html">Tutorials</a>
          	<a class="navbar-brand" href="submissions.html">Call for Papers</a>
			<a class="navbar-brand" href="presenters.html">Presenters</a>
			<a class="navbar-brand" href="contacts.html">Committee</a>
        	</div>
        	<div id="navbar" class="navbar-collapse collapse">
        	</div><!--/.navbar-collapse -->
      	</div>
    	</nav>
    	<div class="container">
        	<h2>ALTA 2018 Programme</h2>
		<!--p> Below is the tentative programme. (This may be subject to change closer to the conference date.)</p-->
		<table class="table">
		<tbody>
			<tr><td colspan="3"><h4>10th December 2018 (Monday) Tutorial</h4></td></tr>
			<!--tr>
			<th scope="row">14:00</th>
			<td colspan="2">Registration</td>
			</tr-->
			<tr>
			<td colspan="3"><b>Tutorial Session</b> (Presenter: Professor  Phil Cohen, Monash University)</br><b><i>Room TBA</i></b></td>
			</tr>
			<tr>
			<th scope="row">14:00</th>
			<td>Tutorial: <a href="http://alta2018.alta.asn.au/tutorials.html#title" target="_blank">Towards Collaborative Dialogue</a></td>
			</tr>
			<tr>
			<th scope="row">17:00</th>
			<td colspan="2">End of Tutorial</td>
			</tr>
			<tr>
			<th scope="row">18:00</th>
			<td colspan="2">Brewery Tour</td>
			</tr>			
			<tr><td colspan="3"><h4>11th December 2018 (Tuesday) Day 1 </h4></td></tr>
			<tr>
			<th scope="row">8:30</th>
			<td colspan="2">Registration</td>
			</tr>
			<tr>
			<th scope="row">9:00</th>
				<td colspan="2"><b>Opening</b></br><b><i>Room TBA</i></b></td>
			</tr>
			<tr>
			<td colspan="3"><b>Keynote 1</b> (Chair: Andrew Trotman)<button type="button" disabled>ADCS</button></br><b><i>Room TBA</i></b></td>
			</tr>
			<tr>
			<th scope="row">9:15</th>
			<td>Jon Degenhardt, eBay</td><td><a href="http://adcs-conference.org/2018/keynotes.html#jon" target="_blank">An Industry Perspective on Search and Search Applications</a></td>
			</tr>
			<tr>
			<th scope="row">10:15</th>
			<td colspan="2">Morning Tea</td>
			</tr>
			<tr>
			<td colspan="3"><b>Session 1: Session A: text mining and applications</b> (Chair: TBA)</br><b><i>Room TBA</i></b></td>
			</tr>
			<tr>
			<th scope="row">10:45</th>
			<td>Rolando Coto Solano, Sally Akevai Nicholas and Samantha Wray</td>
			<td><i>Development of Natural Language Processing Tools for Cook Islands Māori</i><button type="button" disabled>Long Paper</button></td>
			</tr>
			<tr>
			<th scope="row">11:05</th>
			<td>Bayzid Ashik Hossain and Rolf Schwitter</td>
			<td><i>Specifying Conceptual Models Using Restricted Natural Language</i><button type="button" disabled>Long Paper</button></td>
			</tr>
			<tr>
			<th scope="row">11:25</th>
			<td>Jenny McDonald and Adon Moskal</td>
			<td><i>Quantext: a text analysis tool for teachers</i><button type="button" disabled>Presentation</button></td>
			</tr>
			<tr>
			<th scope="row">11:45</th>
			<td>Sudhir Mandarapu</td>
			<td><i>Depression detection in clinical interview transcripts using Natural Language Processing and Deep Neural Networks</i><button type="button" disabled>Presentation</button></td>
			</tr>
			<tr>
			<tr>
			<th scope="row">12:05</th>
			<td colspan="2"><b>Lunch</b></td>
			</tr>
			<tr>
			<td colspan="3"><b>Keynote 2</b> (Chair: Xiuzhen Jenny Zhang)<button type="button" disabled>ALTA</button></br><b><i>Room TBA</i></b></td>
			</tr>
			<tr>
			<th scope="row">13:00</th>
			<td>Associate Professor Alistair Knott, University of Otago</td><td><a href="#knott" target="_blank">Learning to talk like a baby</a></td>
			</tr>
			<tr>
			<th scope="row">14:15</th>
			<td colspan="3"><b>Poster Session</b><button type="button" disabled>ALTA x ADCS</button><br><b><i>Room TBA <!--a href="https://www.qut.edu.au/about/campuses-and-facilities/gardens-point-campus/maps-and-getting-here" target="_blank">(S Block)</a--></i></b></td>
			</tr>	
			<tr>
			<th scope="row">15:15</th>
			<td colspan="2"><b>Afternoon Tea</b></td>
			</tr>
			<tr>
			<th scope="row">16:50</th>
			<td colspan="2">End of Day 1</td>
			</tr>
			<tr>
			<th scope="row">19:00</th>
			<td colspan="2"><b>Hangi (Maori) Dinner</b></td>
			</tr>
			<tr><td colspan="3"><h4>12th December 2017 (Wednesday) Day 2 </h4></td></tr>
			<tr>
			<td colspan="3"><b>Keynote 3</b> (Chair: TBA)<button type="button" disabled>ADCS</button></br><b><i>Room TBA</i></b></td>
			</tr>
			<tr>
			<th scope="row">9:00</th>
			<td>Professor David Bainbridge, University of Waikato</td><td><a href="http://adcs-conference.org/2018/keynotes.html#david" target="_blank">Can You Really Do That? Exploring new ways to interact with Web content and the desktop</a></td>
			</tr>
			<tr>
			<th scope="row">10:15</th>
			<td colspan="2"><b>Morning Tea</b></td>
			</tr>
			<tr>	
			<td colspan="3"><b>Session B: machine translation and speech</b> (Chair: TBA)</br><b><i>Room TBA</i></b></td>
			</tr>
			<tr>
			<th scope="row">10:45</th>
			<td>Cong Duy Vu Hoang, Gholamreza Haffari and Trevor Cohn</td>
			<td><i>Improved Neural Machine Translation using Side Information</i><button type="button" disabled>Long Paper</button><br><button type="button" disabled>Best Paper</button></td>
			</tr>
			<tr>
			<th scope="row">11:05</th>
			<td>Aman Sinha and Radhika Mamidi</td>
			<td><i>Evaluation of Machine Translation Systems for Sarcasm Transfer</i><button type="button" disabled>Presentation</button></td>
			</tr>
			<tr>
			<th scope="row">11:25</th>
			<td>Satoru Tsuge and Shunichi Ishihara</td>
			<td><i>Text-dependent Forensic Voice Comparison: Likelihood Ratio Estimation with the Hidden Markov Model (HMM) and Gaussian Mixture Model – Universal Background Model (GMM-UBM) Approaches</i><button type="button" disabled>Long Paper</button></td>
			</tr>
			<tr>
			<th scope="row">11:45</th>
			<td>Nitika Mathur, Timothy Baldwin and Trevor Cohn</td>
			<td><i>Towards Efficient Machine Translation Evaluation by Modelling Annotators</i><button type="button" disabled>Short Paper</button><br><button type="button" disabled>Best Short Paper</button></td>
			</tr>
			<tr>
			<th scope="row">11:53</th>
			<td>Xuanli He, Quan Tran, William Havard, Laurent Besacier, Ingrid Zukerman and Gholamreza Haffari</td>
			<td><i>Exploring Textual and Speech information in Dialogue Act Classification with Speaker Domain Adaptation</i><button type="button" disabled>Short Paper</button></td>
			</tr>
			<tr>
			<th scope="row">12:05</th>
			<td colspan="2"><b>Lunch</b></td>
			</tr>
			<tr>
			<td colspan="3"><b>Keynote 4</b> (Chair: TBA)<button type="button" disabled>ALTA</button></br><b><i>Room TBA</i></b></td>
			</tr>
			<tr>
			<th scope="row">12:55</th>
			<td>Dr. Kristin Stock, Massey University</td><td><a href="#stock" target="_blank">"Where am I, and what am I doing here?" Extracting geographic information from natural language text</a></td>
			</tr>
			<tr>
			<th scope="row">13:55</th>
			<td colspan="2"><b>Break 10 minutes</b></td>
			</tr>
			<tr>
			<td colspan="3"><b>Session C: shared with ADCS</b> (Chair: TBA)</br><b><i>Room TBA</i></b></td>
			</tr>
			<tr>
			<th scope="row">14:05</th>
			<td>Alfan Farizki Wicaksono and Alistair Moffat</td>
			<td><i>Exploring Interaction Patterns in Job Search</i><button type="button" disabled>ADCS Long Paper</button></td>
			</tr>
			<tr>
			<th scope="row">14:30</th>
			<td>Xavier Holt and Andrew Chisholm</td>
			<td><i>Extracting structured data from invoices</i><button type="button" disabled>ALTA Long Paper</button></td>
			</tr>
			<tr>
			<th scope="row">14:50</th>
			<td>Bevan Koopman, Anthony Nguyen, Danica Cossio, Mary-Jane Courage and Gary Francois</td>
			<td><i>Extracting Cancer Mortality Statistics from Free-text Death Certificates: A View from the Trenches</i><button type="button" disabled>ADCS Short Paper</button></td>
			</tr>
			<tr>
			<th scope="row">15:05</th>
			<td>Hanieh Poostchi and Massimo Piccardi</td>
			<td><i>Cluster Labeling by Word Embeddings and WordNet's Hypernymy</i><button type="button" disabled>ALTA Short Paper</button></td>
			</tr>
			<tr>
			<th scope="row">15:15</th>
			<td colspan="2"><b>Afternoon Tea</b></td>
			</tr>
			

			<td colspan="3"><b>Session D: word semantics and language generation</b> (Chair: TBA)</br><b><i>Room TBA</i></b></td>
			</tr>
			<tr>
			<th scope="row">15:35</th>
			<td>Lance De Vine, Shlomo Geva and Peter Bruza</td>
			<td><i>Unsupervised Mining of Analogical Frames by Constraint Satisfaction</i><button type="button" disabled>Long Paper</button></td>
			</tr>
			<tr>
			<th scope="row">15:55</th>
			<td>Qiongkai Xu, Lizhen Qu and Jiawei Wang</td>
			<td><i>Decoupling Stylistic Language Generation</i><button type="button" disabled>Presentation</button></td>
			</tr>
			<tr>
			<th scope="row">16:15</th>
			<td>Navnita Nandakumar, Bahar Salehi and Timothy Baldwin</td>
			<td><i>A Comparative Study of Embedding Models in Predicting the Compositionality of Multiword Expressions</i><button type="button" disabled>Short Paper</button></td>
			</tr>

			<tr>
			<td colspan="3"><b>Shared Task Session</b> (Chair: Diego Molla-Aliod)</br><b><i>16:25 Room TBA</i></b></td>
			</tr>
			<!--tr>
			<th scope="row">16:25</th>
			<td>Diego Molla-Aliod and Steve Cassidy</td>
			<td><i>Overview of the 2017 ALTA Shared Task: Correcting OCR Errors</i></td>
			</tr>
			<tr>
			<th scope="row"></th>
			<td>Gitansh Khirbat</td>
			<td><i>OCR Post-Processing Text Correction using Simulated Annealing (OPTeCA)</i><button type="button" disabled>Shared Task Winner</button></td>
			</tr>
			<tr>
			<th scope="row"></th>
			<td>Yufei Wang</td>
			<td><i>SuperOCR for ALTA 2017 Shared Task</i></td>	
			</tr-->

			<tr>
			<th scope="row">16:55</th>
			<td colspan="2">Best Paper Awards</td>
			</tr>
			<tr>
			<th scope="row"></th>
			<td colspan="2">Business Meeting</td>
			</tr>
			<tr>
			<th scope="row"></th>
			<td colspan="2">Closing</td>
			</tr>
			<tr>
			<th scope="row">17:20</th>
			<td colspan="2">End of Day 2</td>
			</tr>
			<tr>
			<th scope="row">19:30</th>
			<td colspan="2"><b>Boat Trip</b></td>
			</tr>
		</tbody>
		</table>
    	</div>
	<br>
    	<div class="container">
	<h2 id="invited">Invited Keynotes</h2>
	</div>	
	<div class="container">
		<h3>Title: Learning to talk like a baby</h3>
		<h4 id="knott">Speaker: Associate Professor Alistair Knott, University of Otago / Soul Machines</h4>
		<p><img src="images/ali-grabbing-cup.jpg" alt="Alistair Knott"></p>
		<p align="justify">Alistair Knott is an Associate Professor in the Computer Science department at the University of Otago. He studied Psychology and Philosophy at Oxford University, then took a MSc and PhD in Artificial Intelligence at the University of Edinburgh. His PhD research was on theories of discourse structure, focussing on how coherence relations are signalled by sentence and clause connectives. His postdoc work was in text generation, on Edinburgh University’s ILEX project, which developed one of the first text generators to be deployed on the web. After moving to New Zealand, Ali developed an interest in dialogue models, building a mixed-initiative multi-speaker dialogue system that combined HPSG and Discourse Representation Theory. Aside from these topics, Ali's main research interest for the last 20 years has been in models of how language is implemented in the brain. His focus is on models of the interface between language and the sensorimotor system, that address how it is we can talk about the things we see and do. In 2012 he published a programmatic model of this interface (‘Sensorimotor Cognition and Natural Language Syntax’, MIT Press). This model proposes that certain elements of syntactic structure have their origin in the structure of the sensorimotor routines involved in perceiving events in the world, and in the structure of the circuits which store these events in working memory. In 2017, Ali began working on a commercial contract with the Auckland-based AI startup Soul Machines. This company creates biologically realistic avatars that can engage in dialogues with human users. There is an emphasis on modelling dialogue agents’ physical bodies and sensory systems, and how these interface with actual brain mechanisms.. which makes it an ideal environment for Ali. Ali also works on the ethical and social implications of AI. In January 2016 co-founded the AI and Society discussion group at Otago University. This year he co-founded Otago’s Centre for AI and Public Policy, which is actively engaging with the New Zealand government to provide oversight of the predictive analytics tools used by government departments.</p>
		<h4>Abstract:</h4>
		<p align="justify">In recent years, computational linguists have embraced neural network models, and the vector-based representations of words and meanings they use. But while computational linguists have readily adopted the machinery of neural network models, they have been slower to embrace the original aim of neural network research, which was to understand how brains work. A large community of neural network researchers continues to pursue this ‘cognitive modelling’ aim, with very interesting results. But the work of these more cognitively minded modellers has not yet percolated deeply into computational linguistics. 

In my talk, I will argue the cognitive modelling tradition of neural networks has much to offer computational linguistics. I will outline a research programme that situates language modelling in a broader cognitive context. The programme is distinctive in two ways. Firstly, the initial object of study is a baby, rather than an adult. Computational linguistics models typically aim to reproduce adult linguistic competence in a single training process, that presents an ‘empty’ network with a corpus of mature language. I’ll argue that this training process doesn’t correspond to anything in human experience, and that we should instead aim to model a more gradual developmental process, that first achieves babylike language, then childlike language, and so on. Secondly, the new programme studies the baby's language system as it interfaces with her other cognitive systems, rather than by itself. It pays particular attention to the sensory and motor systems through which a baby engages with the physical world, which are the primary means by which it activates semantic representations. I’ll argue that the structure of these sensorimotor systems, as expressed in neural network models, offer interesting insights about certain aspects of linguistic structure. I will conclude by demoing a model of the interface between language and the sensorimotor system, as it operates in a baby at an early stage of language learning.</p>
	</div>
	<br>
	<div class="container">
		<h3>Title: "Where am I, and what am I doing here?" Extracting geographic information from natural language text</h3>
		<h4 id="stock">Speaker: Dr Kristin Stock, Massey University</h4>
		<p><img src="images/KristinStock.jpg" alt="Kristin Stock"></p>
		<p align="justify"> Dr Kristin Stock is Director of the Massey Geoinformatics Collaboratory, and a Senior Lecturer in Information Technology. She has 25 years’ experience in geospatial information management in the private, public and University sectors, has led a number of large international geospatial projects in Europe, Australia and New Zealand and played a key role in Europe-wide data sharing projects such as INSPIRE and EuroGEOSS. Her research focuses on geospatial natural language in collaboration with researchers in the Europe and Australia, most specifically on the development of methods for the extracting location information from text in order to map objects and events that cannot otherwise be located.  Dr Stock was recently AI on a $2.74m MBIE Research Programme grant to develop a Maori land classification system, as well as receiving grants from MBIE (Our Land and Water National Science Challenge), the European Union FP7 programme and numerous industry-funders.</p>
		<h4>Abstract:</h4>
		<p align="justify">The extraction of place names (toponyms) from natural language text has received a lot of attention in recent years, but location is frequently described in more complex ways, often using other objects as reference points.  Examples include: ‘The accident occurred opposite the Orewa Post Office, near the pedestrian crossing’ or ‘the sample was collected on the west bank of the Waikato River, about 3km upstream from Huntly’.  These expressions can be vague, imprecise, underspecified, rely on access to information about other objects in the environment, and the semantics of spatial relations like ‘opposite’ and ‘on’ are still far from clear.  Furthermore, many of these kinds of expressions are context sensitive, and aspects such as scale, geometry and type of geographic feature may influence the way the expression is understood.  Both machine learning and rule-based approaches have been developed to try to firstly parse expressions of this kind, and secondly to determine the geographic location that the expression refers to.  Several relevant projects will be discussed, including the development of a semantic rather than syntactic approach to parsing geographic location descriptions; the creation of a manually annotated training set of geographic language; the challenges highlighted from human descriptions of location in the emergency services context; the interpretation and geocoding of descriptions of flora and fauna specimen collections; the development of models of spatial relations using social media data and the use of instance-based learning to interpret complex location descriptions.</p>
	</div>

	<div class="container">
        	<h2 id="accepted-papers">ALTA 2018 Accepted Papers</h2>        
        	<h3>Long Papers</h3>
    		<ul>
			<li>Improved Neural Machine Translation using Side Information. <i>Cong Duy Vu Hoang, Gholamreza Haffari and Trevor Cohn</i></li>
			<li>Text-dependent Forensic Voice Comparison: Likelihood Ratio Estimation with the Hidden Markov Model (HMM) and Gaussian Mixture Model. <i>Satoru Tsuge and Shunichi Ishihara</i></li>
			<li>Development of Natural Language Processing Tools for Cook Islands Māori. <i>Rolando Coto Solano, Sally Akevai Nicholas and Samantha Wray</i></li>
			<li>Unsupervised Mining of Analogical Frames by Constraint Satisfaction. <i>Lance De Vine, Shlomo Geva and Peter Bruza</i></li>
			<li>Specifying Conceptual Models Using Restricted Natural Language. <i>Bayzid Ashik Hossain and Rolf Schwitter</i></li>
			<li>Extracting structured data from invoices. <i>Xavier Holt and Andrew Chisholm</i></li>
			</ul>        	
        	<h3>Short Papers</h3>
        	<ul>
			<li>Exploring Textual and Speech information in Dialogue Act Classification with Speaker Domain Adaptation. <i>Xuanli He, Quan Tran, William Havard, Laurent Besacier, Ingrid Zukerman and Gholamreza Haffari</i></li>
			<li>Cluster Labeling by Word Embeddings and WordNet's Hypernymy. <i>Hanieh Poostchi and Massimo Piccardi</i></li>
			<li>A Comparative Study of Embedding Models in Predicting the Compositionality of Multiword Expressions. <i>Navnita Nandakumar, Bahar Salehi and Timothy Baldwin</i></li>
			<li>Towards Efficient Machine Translation Evaluation by Modelling Annotators. <i>Nitika Mathur, Timothy Baldwin and Trevor Cohn</i></li>
			</ul>    	
    		<!--p> Full program will be released as soon as it is finalised.</p-->
    		<!--p>The <a href="https://aclanthology.info/events/alta-2017" target="_blank"> proceedings </a> is now available on the ACL anthology.</p-->
    	</div>
   
   	<footer class="attrib-footer">
        	<p>&copy; ALTA 2018 | The banner image of The University of Otago was adapted from <a href="https://www.otago.ac.nz/otagobulletin/news/otago042380.html" target="_blank">a photo taken by Michael Robertson</a> and is used under the <a href="https://creativecommons.org/licenses/by-nc/2.0/" target="_blank">Creative Commons 2.0 Non-Commercial Generic Licence</a></p>
      	</footer>


    	<!-- Bootstrap core JavaScript
    	================================================== -->
    	<!-- Placed at the end of the document so the pages load faster -->
    	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    	<script src="../../dist/js/bootstrap.min.js"></script>
    	<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    	<script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  	</body>
</html>

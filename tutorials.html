<!DOCTYPE html>
<html lang="en">
	<head>
    	<meta charset="utf-8">
    	<meta http-equiv="X-UA-Compatible" content="IE=edge">
    	<meta name="viewport" content="width=device-width, initial-scale=1">
    	<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    	<meta name="description" content="">
    	<meta name="author" content="">
    	<link rel="icon" href="logos/logo_sm.jpg">

    	<title>ALTA 2018</title>

    	<!-- Bootstrap core CSS -->
    	<link href="css/bootstrap.css" rel="stylesheet">

    	<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    	<!--[if lt IE 9]>
      	<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      	<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    	<![endif]-->
  	</head>

  	<body>
    	<div class="jumbotron">
      		<div class="container">
        	<br>
        	<br>
        	<h2>16th Annual Workshop of <br>The Australasian Language Technology Association</h2>
		<h3>The University of Otago, Dunedin, New Zealand</h3>
		<h3>10th - 12th December 2018</h3>
      		</div>
    	</div>
    
    	<nav class="navbar navbar-inverse navbar-fixed-top">
      	<div class="container">
        	<div class="navbar-header">
          	<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            	<span class="sr-only">Toggle navigation</span>
            	<span class="icon-bar"></span>
            	<span class="icon-bar"></span>
            	<span class="icon-bar"></span>
          	</button>
          	<a class="navbar-brand" href="index.html">Home</a>
          	<a class="navbar-brand" href="accepted_papers.html">Programme</a>
          	<a class="navbar-brand" href="attending.html">Attending</a>
		  	<a class="navbar-brand" href="tutorials.html">Tutorials</a>
          	<a class="navbar-brand" href="submissions.html">Call for Papers</a>
			<!--a class="navbar-brand" href="presenters.html">Presenters</a-->
          	<a class="navbar-brand" href="contacts.html">Committee</a>
		</div>
		<div id="navbar" class="navbar-collapse collapse">
        	</div><!--/.navbar-collapse -->
      	</div>
    	</nav>

    	<div class="container">
    	<!--p> Tutorials will be released as soon as it is finalised.</p-->
      	<div class="row">
       	<h2>Overview</h2>
		<p align="justify">Tutorials will take place on 10th December (2-5pm), immediately before the ALTA and ADCS workshops. These tutorials feature advanced methods in text processing, and will be pitched to a general audience. All workshop participants are encouraged to attend, both students and staff. </p>
		<br>
		<h3> Title: Towards Collaborative Dialogue </h3>
		<h4> Abstract</h4>
		<p align="justify">This tutorial will discuss a program of research for building collaborative dialogue systems, which are a core part of virtual assistants. I will briefly discuss the strengths and limitations of current approaches to dialogue, including neural network-based and slot-filling approaches, but then concentrate on approaches that treat conversation as planned collaborative behaviour. Collaborative interaction involves recognizing someone’s goals, intentions, and plans, and then performing actions to facilitate them. People have learned this basic capability at a very young age and are expected to be helpful as part of ordinary social interaction. In general, people’s plans involve both speech acts (such as requests, questions, confirmations, etc.) and physical acts. When collaborative behavior is applied to speech acts, people infer the reasons behind their interlocutor’s utterances and attempt to ensure their success. Such reasoning is apparent when an information agent answers the question “Do you know where the Sydney flight leaves?” with “Yes, Gate 8, and it’s running 20 minutes late.” It is also apparent when one asks “where is the nearest petrol station?” and the interlocutor answers “2 kilometers to your right” even though it isn’t the closest, but rather the closest one that is open. In this latter case, the respondent has inferred that you want to buy petrol, not just to know the location of the station. In both cases, the literal and truthful answer is not cooperative. 
		In order to build systems that collaborate with humans or other artificial agents, a system needs components for planning, plan recognition, and for reasoning about agents’ mental states (beliefs, desires, goals, intentions, obligations, etc.). In this tutorial, I will discuss current theory and practice of such collaborative belief-desire-intention architectures, and demonstrate how they can form the basis for an advanced collaborative dialogue manager. In such an approach, systems reason about what they plan to say, and why the user said what s/he did. Because there is a plan standing behind the system’s utterances, it is able to explain its reasoning. Finally, we will discuss potential methods for incorporating such a plan-based approach with machine-learned approaches.</p>
		<h4> Tutorial Speaker: Dr. Phil Cohen, Professor and Director, Laboratory for Dialogue Research, Faculty of Information Technology, Monash University </h3>
		<p><img src="images/Phil-Cohen.png" alt="Phil Cohen"></p>
		<h4> Speaker bio: </h3>
		<p align="justify">Dr. Phil Cohen has long been engaged in the AI subfields of human-computer dialogue, multimodal interaction, and multiagent systems. He is a Fellow of the Association for the Advancement of Artificial Intelligence, and a past President of the Association for Computational Linguistics. Currently, he directs the Laboratory for Dialogue Research at Monash University. Formerly Chief Scientist, AI and Sr. Vice President for Advanced Technology at Voicebox Technologies, he has also held positions at Adapx Inc (founder), the Oregon Graduate Institute (Professor), the Artificial Intelligence Center of SRI International (Sr. Research Scientist and Program Director, Natural Language Program), Fairchild Laboratory for Artificial Intelligence, and Bolt Bernanek and Newman. His accomplishments include co-developing influential theories of intention, collaboration, and speech acts, co-developing and deploying high-performance multimodal systems to the US Government, and conceiving and leading the project at SRI International that developed the Open Agent Architecture, which eventually became Siri. Cohen has published more than 150 refereed papers, with more than 16,800 citations, and received 7 patents. His paper with Prof. Hector Levesque “Intention is Choice with Commitment” was awarded the inaugural Influential Paper Award from the International Foundation for Autonomous Agents and Multi-Agent Systems. Most recently, he is the recipient of the 2017 Sustained Accomplishment Award from the International Conference on Multimodal Interaction. At Voicebox, Cohen led a team engaged in semantic parsing, and human-computer dialogue.</p>
		<br>
	</div>
    	</div> <!-- /container -->
    
    <footer class="attrib-footer">
        	<p>&copy; ALTA 2018 | The banner image of The University of Otago was adapted from <a href="https://www.otago.ac.nz/otagobulletin/news/otago042380.html" target="_blank">a photo taken by Michael Robertson</a> and is used under the <a href="https://creativecommons.org/licenses/by-nc/2.0/" target="_blank">Creative Commons 2.0 Non-Commercial Generic Licence</a></p>
      	</footer>

    	<!-- Bootstrap core JavaScript
    	================================================== -->
    	<!-- Placed at the end of the document so the pages load faster -->
    	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    	<script src="../../dist/js/bootstrap.min.js"></script>
    	<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    	<script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  	</body>
</html>
